{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc233c42-4866-4d15-adf2-686eca75a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "import logging\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(filename=\"5.model_build.log\", level=logging.INFO, format='%(asctime)s %(message)s',datefmt=\"%Y-%m-%d %H:%M:%S\")\n",
    "features = ['TSH', 'TT4', 'T4U', 'FTI']\n",
    "try:\n",
    "    logging.info(\"model build started\")\n",
    "    try:\n",
    "        x_train =  pd.read_csv(\"x_train.csv\")\n",
    "        y_train =  pd.read_csv(\"y_train.csv\")\n",
    "        logging.info(\"Sucessfully loading the train dataset========================\")\n",
    "    except Exception as e:\n",
    "        logging.info(f\"The error raise when loading the train dataset:{e}========================\")\n",
    "    try:\n",
    "        x_test =  pd.read_csv(\"x_test.csv\")\n",
    "        y_test =  pd.read_csv(\"y_test.csv\")\n",
    "        logging.info(\"Sucessfully loading the test dataset========================\")\n",
    "    except Exception as e:\n",
    "        logging.info(f\"The error raise when loading the test dataset:{e}========================\")\n",
    "    try:\n",
    "        pipe4 = Pipeline([(\"XGboost\", XGBClassifier())])\n",
    "        pipe6 = Pipeline([(\"random_forest\", RandomForestClassifier())])\n",
    "        logging.info(\"Sucessfully created pipeline=================================\")\n",
    "    except Exception as e:\n",
    "        logging.info(f\"The error raise when  created pipeline:{e}========================\")\n",
    "        \n",
    "    def finding_best_parameter_rf(model, x, y, final_features):\n",
    "        try:\n",
    "            parameters= { \n",
    "                \"random_forest__criterion\":[\"gini\",\"entropy\"],\n",
    "                \"random_forest__n_estimators\": [10, 100, 1000],\n",
    "                \"random_forest__max_depth\":[5,8,15,25,30,None],\n",
    "                \"random_forest__min_samples_leaf\":[1,2,5,10,15,100],\n",
    "                \"random_forest__max_leaf_nodes\": [2, 5,10]\n",
    "            }\n",
    "            best_parameter_model = RandomizedSearchCV(model, param_distributions=parameters, cv=3)\n",
    "            best_parameter_model.fit(x[final_features], y)\n",
    "            logging.info(best_parameter_model.best_params_)\n",
    "            logging.info(best_parameter_model.best_score_)\n",
    "            return best_parameter_model\n",
    "        except Exception as e:\n",
    "            logging.info(f\"The error raise when fit the dataset:{e}========================\")\n",
    "    random_forest =finding_best_parameter_rf(pipe6, x_train, y_train, features)\n",
    "    features = [\"FTI\", \"TSH\", \"TT4\", \"T4U\"] \n",
    "    def finding_best_parameter_xb(model, x, y, final_features):\n",
    "        try:\n",
    "            parameters= { \n",
    "                'XGboost__max_depth': [3,4,5,7,10,15,],\n",
    "                'XGboost__learning_rate': [0.001, 0.0003, 0.005],\n",
    "                'XGboost__n_estimators': [100, 150, 80, 200],\n",
    "                'XGboost__colsample_bytree': [0.3, 0.5, 0.7, 0.9]\n",
    "            }\n",
    "            best_parameter_model = RandomizedSearchCV(model, param_distributions=parameters, cv=5)\n",
    "            best_parameter_model.fit(x[final_features], y)\n",
    "            logging.info(best_parameter_model.best_params_)\n",
    "            logging.info(best_parameter_model.best_score_)\n",
    "            logging.info(\"model build completed\")\n",
    "            return best_parameter_model\n",
    "        except Exception as e:\n",
    "            logging.info(f\"The error raise when fit the dataset:{e}========================\")\n",
    "    xgboost = finding_best_parameter_xb(pipe4, x_train, y_train, features)\n",
    "    try:\n",
    "        pickle.dump(random_forest , open('RandomForestClassifier.pkl','wb'))\n",
    "        logging.info(\"Successfully saved Random forest\")\n",
    "    except Exception as e:\n",
    "            logging.info(f\"The error raise when saved Random forest:{e}========================\")\n",
    "except Exception as e:\n",
    "    logging.info(f\"model build NOT completed:{e}========================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
